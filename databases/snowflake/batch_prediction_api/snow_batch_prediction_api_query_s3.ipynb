{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Snowflake Batch Prediction API Snowflake S3 scoring job\n",
    "\n",
    "v1.0 Mike Taveirne (doyouevendata) 3/21/2020\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:18:54.798810Z",
     "start_time": "2020-03-22T08:18:53.890013Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "import snowflake.connector\n",
    "\n",
    "import my_creds\n",
    "#from imp import reload\n",
    "#reload(my_creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:18:54.805793Z",
     "start_time": "2020-03-22T08:18:54.801163Z"
    }
   },
   "outputs": [],
   "source": [
    "# datarobot parameters\n",
    "API_KEY = my_creds.API_KEY\n",
    "USERNAME = my_creds.USERNAME\n",
    "DEPLOYMENT_ID = my_creds.DEPLOYMENT_ID\n",
    "DATAROBOT_KEY = my_creds.DATAROBOT_KEY\n",
    "# replace with the load balancer for your prediction instance(s)\n",
    "DR_PREDICTION_HOST = my_creds.DR_PREDICTION_HOST\n",
    "DR_APP_HOST = 'https://app.datarobot.com'\n",
    "\n",
    "DR_MODELING_HEADERS = {'Content-Type': 'application/json', 'Authorization': 'token %s' % API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:18:54.815637Z",
     "start_time": "2020-03-22T08:18:54.808182Z"
    }
   },
   "outputs": [],
   "source": [
    "# snowflake parameters\n",
    "SNOW_ACCOUNT = my_creds.SNOW_ACCOUNT\n",
    "SNOW_USER = my_creds.SNOW_USER\n",
    "SNOW_PASS = my_creds.SNOW_PASS\n",
    "SNOW_DB = 'TITANIC'\n",
    "SNOW_SCHEMA = 'PUBLIC'\n",
    "\n",
    "# ETL parameters\n",
    "JOB_NAME = 'pass_scoring'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-20T17:44:02.182057Z",
     "start_time": "2020-03-20T17:44:02.177036Z"
    }
   },
   "source": [
    "### Save S3 Credentials for Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:18:57.989779Z",
     "start_time": "2020-03-22T08:18:56.281611Z"
    }
   },
   "outputs": [],
   "source": [
    "# s3 credential creation\n",
    "json = {\n",
    "    \"credentialType\": \"s3\",\n",
    "    \"awsAccessKeyId\": my_creds.AWS_ACCESS_KEY_ID_SUPPORT_STATIC,\n",
    "    \"awsSecretAccessKey\": my_creds.AWS_SECRET_KEY_SUPPORT_STATIC,\n",
    "    \"name\": \"s3_community\"\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "        url = DR_APP_HOST + '/api/v2/credentials/',\n",
    "        headers=DR_MODELING_HEADERS,\n",
    "        json=json\n",
    "    )\n",
    "\n",
    "CREDENTIALS_ID = response.json()['credentialId']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T08:40:27.647632Z",
     "start_time": "2020-03-21T08:40:27.644075Z"
    }
   },
   "source": [
    "### Retrieve Existing S3 Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:01.528853Z",
     "start_time": "2020-03-22T08:19:00.208722Z"
    }
   },
   "outputs": [],
   "source": [
    "# s3 credential lookup\n",
    "CREDENTIALS = 's3_community'\n",
    "\n",
    "response = requests.get(\n",
    "        DR_APP_HOST + '/api/v2/credentials/',\n",
    "        headers=DR_MODELING_HEADERS,\n",
    "    )\n",
    "\n",
    "df = pd.io.json.json_normalize(response.json()['data'])[['credentialId', 'name']]\n",
    "CREDENTIALS_ID = df[df['name'] == CREDENTIALS]['credentialId'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T13:08:30.545546Z",
     "start_time": "2020-03-21T13:08:30.516941Z"
    }
   },
   "source": [
    "### Extract Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:09.675161Z",
     "start_time": "2020-03-22T08:19:03.968816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x1231df210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a connection\n",
    "ctx = snowflake.connector.connect(\n",
    "    user=SNOW_USER,\n",
    "    password=SNOW_PASS,\n",
    "    account=SNOW_ACCOUNT,\n",
    "    database=SNOW_DB,\n",
    "    schema=SNOW_SCHEMA,\n",
    "    protocol='https'\n",
    ")\n",
    "\n",
    "# create a cursor\n",
    "cur = ctx.cursor()\n",
    "\n",
    "# execute sql to get start/end timestamps to use\n",
    "sql = \"select last_ts_scored_through, current_timestamp::TIMESTAMP_NTZ cur_ts \" \\\n",
    "    \"from etl_history \" \\\n",
    "    \"where job_nm = '{job}' \" \\\n",
    "    \"order by last_ts_scored_through desc \" \\\n",
    "    \"limit 1 \".format(job=JOB_NAME)\n",
    "cur.execute(sql)\n",
    "\n",
    "# fetch results into dataframe\n",
    "df = cur.fetch_pandas_all()\n",
    "start_ts = df['LAST_TS_SCORED_THROUGH'][0]\n",
    "end_ts = df['CUR_TS'][0]\n",
    "\n",
    "# execute sql to dump data into a single file in S3 stage bucket\n",
    "# AWS single file snowflake limit 5 GB\n",
    "sql = \"COPY INTO @S3_SUPPORT/titanic/community/\" + JOB_NAME + \".csv \" \\\n",
    "    \"from  \" \\\n",
    "    \"( \" \\\n",
    "    \"  select passengerid, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked \" \\\n",
    "    \"  from passengers_500k_ts \" \\\n",
    "    \"  where nvl(updt_ts, crt_ts) >= '{start}' \" \\\n",
    "    \"  and nvl(updt_ts, crt_ts) < '{end}' \" \\\n",
    "    \") \" \\\n",
    "    \"file_format = (format_name='default_csv' compression='none') header=true overwrite=true single=true;\".format(start=start_ts, end=end_ts)\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T08:40:27.963686Z",
     "start_time": "2020-03-21T08:39:01.550Z"
    }
   },
   "source": [
    "### Create DataRobot Session and Running Batch Prediction API Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:09.679827Z",
     "start_time": "2020-03-22T08:19:09.676980Z"
    }
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers = {\n",
    "    'Authorization': 'Bearer {}'.format(API_KEY),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:09.687554Z",
     "start_time": "2020-03-22T08:19:09.682432Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = 's3://'+ my_creds.S3_BUCKET + '/titanic/community/' + JOB_NAME + '.csv'\n",
    "OUTPUT_FILE = 's3://'+ my_creds.S3_BUCKET + '/titanic/community/' + JOB_NAME + '_scored.csv'\n",
    "\n",
    "job_details = {\n",
    "    'deploymentId': DEPLOYMENT_ID,\n",
    "    'passthroughColumns': ['PASSENGERID'],\n",
    "    'numConcurrent': 4,\n",
    "    \"predictionInstance\" : {\n",
    "        \"hostName\": DR_PREDICTION_HOST,\n",
    "        \"datarobotKey\": DATAROBOT_KEY\n",
    "    },\n",
    "    'intakeSettings': {\n",
    "        'type': 's3',\n",
    "        'url': INPUT_FILE,\n",
    "        'credentialId': CREDENTIALS_ID\n",
    "    },\n",
    "    'outputSettings': {\n",
    "        'type': 's3',\n",
    "        'url': OUTPUT_FILE,\n",
    "        'credentialId': CREDENTIALS_ID\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:12.042595Z",
     "start_time": "2020-03-22T08:19:09.689458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued batch job: https://app.datarobot.com/api/v2/batchPredictions/123456789012345678161/\n"
     ]
    }
   ],
   "source": [
    "response = session.post(\n",
    "        DR_APP_HOST + '/api/v2/batchPredictions',\n",
    "        json=job_details\n",
    "    )\n",
    "\n",
    "job = response.json()\n",
    "print('queued batch job: {}'.format(job['links']['self']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor S3 Scoring Status and Return Control Upon Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:19:41.966639Z",
     "start_time": "2020-03-22T08:19:14.744800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed INITIALIZING\n",
      "completed RUNNING\n",
      "status is now COMPLETED\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 202:\n",
    "\n",
    "    while job['status'] == 'INITIALIZING':\n",
    "        time.sleep(3)\n",
    "        response = session.get(job['links']['self'])\n",
    "        response.raise_for_status()\n",
    "        job = response.json()\n",
    "        \n",
    "    print('completed INITIALIZING')\n",
    "        \n",
    "    if job['status'] == 'RUNNING':\n",
    "\n",
    "        while job['status'] == 'RUNNING':\n",
    "            time.sleep(1)\n",
    "            response = session.get(job['links']['self'])\n",
    "            response.raise_for_status()\n",
    "            job = response.json()\n",
    "            \n",
    "    print('completed RUNNING')\n",
    "    print('status is now {status}'.format(status=job['status']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:17:10.883806Z",
     "start_time": "2020-03-22T08:17:10.880532Z"
    }
   },
   "source": [
    "### Truncate and Reload STG Staging Table with Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:20:16.576208Z",
     "start_time": "2020-03-22T08:20:13.950591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<snowflake.connector.cursor.SnowflakeCursor at 0x1233d0f10>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x1231244d0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-statement executions\n",
    "# https://docs.snowflake.com/en/user-guide/python-connector-api.html#execute_string\n",
    "\n",
    "# truncate and load STG schema table with scored results\n",
    "sql = \"truncate titanic.stg.PASSENGERS_SCORED_BATCH_API; \" \\\n",
    "    \" copy into titanic.stg.PASSENGERS_SCORED_BATCH_API from @S3_SUPPORT/titanic/community/\" + JOB_NAME + \"_scored.csv\" \\\n",
    "    \" FILE_FORMAT = 'DEFAULT_CSV' ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;\"\n",
    "ctx.execute_string(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:17:34.107279Z",
     "start_time": "2020-03-22T08:17:34.104603Z"
    }
   },
   "source": [
    "### Update Presentation Target Table With Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:20:24.458764Z",
     "start_time": "2020-03-22T08:20:16.578812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<snowflake.connector.cursor.SnowflakeCursor at 0x12326dd90>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x1233c9e90>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x10f8b2210>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x1233c9dd0>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update target presentation table and ETL history table in transaction\n",
    "\n",
    "sql = \\\n",
    "    \"begin; \" \\\n",
    "    \"update titanic.public.passengers_500k_ts trg \" \\\n",
    "    \"set trg.survival = src.survived_1_prediction \" \\\n",
    "    \"from titanic.stg.PASSENGERS_SCORED_BATCH_API src \" \\\n",
    "    \"where src.passengerid = trg.passengerid; \" \\\n",
    "    \"insert into etl_history values ('{job}', '{run_through_ts}'); \" \\\n",
    "    \"commit; \".format(job=JOB_NAME, run_through_ts=end_ts)\n",
    "ctx.execute_string(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_env)",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
