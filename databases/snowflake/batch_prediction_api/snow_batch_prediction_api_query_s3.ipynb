{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Snowflake Batch Prediction API Snowflake S3 scoring job\n",
    "\n",
    "v1.0 Mike Taveirne (doyouevendata) 3/21/2020\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:07.606148Z",
     "start_time": "2020-03-30T04:52:06.589685Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from pandas.io.json import json_normalize\n",
    "import snowflake.connector\n",
    "\n",
    "import my_creds\n",
    "#from imp import reload\n",
    "#reload(my_creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:09.691281Z",
     "start_time": "2020-03-30T04:52:09.687573Z"
    }
   },
   "outputs": [],
   "source": [
    "# datarobot parameters\n",
    "API_KEY = my_creds.API_KEY\n",
    "USERNAME = my_creds.USERNAME\n",
    "DEPLOYMENT_ID = my_creds.DEPLOYMENT_ID\n",
    "DATAROBOT_KEY = my_creds.DATAROBOT_KEY\n",
    "# replace with the load balancer for your prediction instance(s)\n",
    "DR_PREDICTION_HOST = my_creds.DR_PREDICTION_HOST\n",
    "DR_APP_HOST = 'https://app.datarobot.com'\n",
    "\n",
    "DR_MODELING_HEADERS = {'Content-Type': 'application/json', 'Authorization': 'token %s' % API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:10.530886Z",
     "start_time": "2020-03-30T04:52:10.526760Z"
    }
   },
   "outputs": [],
   "source": [
    "# snowflake parameters\n",
    "SNOW_ACCOUNT = my_creds.SNOW_ACCOUNT\n",
    "SNOW_USER = my_creds.SNOW_USER\n",
    "SNOW_PASS = my_creds.SNOW_PASS\n",
    "SNOW_DB = 'TITANIC'\n",
    "SNOW_SCHEMA = 'PUBLIC'\n",
    "\n",
    "# ETL parameters\n",
    "JOB_NAME = 'pass_scoring'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve or Create S3 Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:14.934332Z",
     "start_time": "2020-03-30T04:52:14.925574Z"
    }
   },
   "outputs": [],
   "source": [
    "# get a saved credential set, return None if not found\n",
    "def dr_get_catalog_credentials(name, cred_type):\n",
    "    if cred_type not in ['basic', 's3']:\n",
    "        print('credentials type must be: basic, s3 - value passed was {ct}'.format(ct=cred_type))\n",
    "        return None\n",
    "    \n",
    "    credentials_id = None\n",
    "\n",
    "    response = requests.get(\n",
    "            DR_APP_HOST + '/api/v2/credentials/',\n",
    "            headers=DR_MODELING_HEADERS,\n",
    "        )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        df = pd.io.json.json_normalize(response.json()['data'])[['credentialId', 'name', 'credentialType']]\n",
    "\n",
    "        if df[(df['name'] == name) & (df['credentialType'] == cred_type)]['credentialId'].size > 0:\n",
    "            credentials_id = df[(df['name'] == name) & (df['credentialType'] == cred_type)]['credentialId'].iloc[0]\n",
    "     \n",
    "    else:\n",
    "\n",
    "        print('Request failed; http error {code}: {content}'.format(code=response.status_code, content=response.content))\n",
    "\n",
    "    return credentials_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:15.636883Z",
     "start_time": "2020-03-30T04:52:15.629505Z"
    }
   },
   "outputs": [],
   "source": [
    "# create credentials set\n",
    "def dr_create_catalog_credentials(name, cred_type, user, password, token=None):\n",
    "    if cred_type not in ['basic', 's3']:\n",
    "        print('credentials type must be: basic, s3 - value passed was {ct}'.format(ct=cred_type))\n",
    "        return None\n",
    "    \n",
    "    if cred_type == 'basic':  \n",
    "        json = {\n",
    "            \"credentialType\": cred_type,\n",
    "            \"user\": user,\n",
    "            \"password\": password,\n",
    "            \"name\": name\n",
    "        }\n",
    "    elif cred_type == 's3' and token != None:  \n",
    "        json = {\n",
    "            \"credentialType\": cred_type,\n",
    "            \"awsAccessKeyId\": user,\n",
    "            \"awsSecretAccessKey\": password,\n",
    "            \"awsSessionToken\": token,\n",
    "            \"name\": name\n",
    "        }\n",
    "    elif cred_type == 's3' and token == None:  \n",
    "        json = {\n",
    "            \"credentialType\": cred_type,\n",
    "            \"awsAccessKeyId\": user,\n",
    "            \"awsSecretAccessKey\": password,\n",
    "            \"name\": name\n",
    "        }\n",
    "        \n",
    "    response = requests.post(\n",
    "        url = DR_APP_HOST + '/api/v2/credentials/',\n",
    "        headers=DR_MODELING_HEADERS,\n",
    "        json=json\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 201:\n",
    "\n",
    "        return response.json()['credentialId']\n",
    "        \n",
    "    else:\n",
    "\n",
    "        print('Request failed; http error {code}: {content}'.format(code=response.status_code, content=response.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:18.228929Z",
     "start_time": "2020-03-30T04:52:18.225083Z"
    }
   },
   "outputs": [],
   "source": [
    "# get or create a credential set\n",
    "def dr_get_or_create_catalog_credentials(name, cred_type, user, password, token=None):\n",
    "    cred_id = dr_get_catalog_credentials(name, cred_type)\n",
    "    \n",
    "    if cred_id == None:\n",
    "        return dr_create_catalog_credentials(name, cred_type, user, password, token=None)\n",
    "    else:\n",
    "        return cred_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T04:52:20.762300Z",
     "start_time": "2020-03-30T04:52:18.896119Z"
    }
   },
   "outputs": [],
   "source": [
    "credentials_id = dr_get_or_create_catalog_credentials('s3_community', \n",
    "                                                      's3', my_creds.SNOW_USER, my_creds.SNOW_PASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T13:08:30.545546Z",
     "start_time": "2020-03-21T13:08:30.516941Z"
    }
   },
   "source": [
    "### Extract Data to S3 via Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:11.565105Z",
     "start_time": "2020-03-30T05:08:06.110403Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x11c600d50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a connection\n",
    "ctx = snowflake.connector.connect(\n",
    "    user=SNOW_USER,\n",
    "    password=SNOW_PASS,\n",
    "    account=SNOW_ACCOUNT,\n",
    "    database=SNOW_DB,\n",
    "    schema=SNOW_SCHEMA,\n",
    "    protocol='https'\n",
    ")\n",
    "\n",
    "# create a cursor\n",
    "cur = ctx.cursor()\n",
    "\n",
    "# execute sql to get start/end timestamps to use\n",
    "sql = \"select last_ts_scored_through, current_timestamp::TIMESTAMP_NTZ cur_ts \" \\\n",
    "    \"from etl_history \" \\\n",
    "    \"where job_nm = '{job}' \" \\\n",
    "    \"order by last_ts_scored_through desc \" \\\n",
    "    \"limit 1 \".format(job=JOB_NAME)\n",
    "cur.execute(sql)\n",
    "\n",
    "# fetch results into dataframe\n",
    "df = cur.fetch_pandas_all()\n",
    "start_ts = df['LAST_TS_SCORED_THROUGH'][0]\n",
    "end_ts = df['CUR_TS'][0]\n",
    "\n",
    "# execute sql to dump data into a single file in S3 stage bucket\n",
    "# AWS single file snowflake limit 5 GB\n",
    "sql = \"COPY INTO @S3_SUPPORT/titanic/community/\" + JOB_NAME + \".csv \" \\\n",
    "    \"from  \" \\\n",
    "    \"( \" \\\n",
    "    \"  select passengerid, pclass, name, sex, age, sibsp, parch, ticket, fare, cabin, embarked \" \\\n",
    "    \"  from passengers_500k_ts \" \\\n",
    "    \"  where nvl(updt_ts, crt_ts) >= '{start}' \" \\\n",
    "    \"  and nvl(updt_ts, crt_ts) < '{end}' \" \\\n",
    "    \") \" \\\n",
    "    \"file_format = (format_name='default_csv' compression='none') header=true overwrite=true single=true;\".format(start=start_ts, end=end_ts)\n",
    "cur.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-21T08:40:27.963686Z",
     "start_time": "2020-03-21T08:39:01.550Z"
    }
   },
   "source": [
    "### Create DataRobot Session and Running Batch Prediction API Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:11.571546Z",
     "start_time": "2020-03-30T05:08:11.567287Z"
    }
   },
   "outputs": [],
   "source": [
    "session = requests.Session()\n",
    "session.headers = {\n",
    "    'Authorization': 'Bearer {}'.format(API_KEY)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:11.581573Z",
     "start_time": "2020-03-30T05:08:11.573869Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = 's3://'+ my_creds.S3_BUCKET + '/titanic/community/' + JOB_NAME + '.csv'\n",
    "OUTPUT_FILE = 's3://'+ my_creds.S3_BUCKET + '/titanic/community/' + JOB_NAME + '_scored.csv'\n",
    "\n",
    "job_details = {\n",
    "    'deploymentId': DEPLOYMENT_ID,\n",
    "    'passthroughColumns': ['PASSENGERID'],\n",
    "    'numConcurrent': 4,\n",
    "    \"predictionInstance\" : {\n",
    "        \"hostName\": DR_PREDICTION_HOST,\n",
    "        \"datarobotKey\": DATAROBOT_KEY\n",
    "    },\n",
    "    'intakeSettings': {\n",
    "        'type': 's3',\n",
    "        'url': INPUT_FILE,\n",
    "        'credentialId': credentials_id\n",
    "    },\n",
    "    'outputSettings': {\n",
    "        'type': 's3',\n",
    "        'url': OUTPUT_FILE,\n",
    "        'credentialId': credentials_id\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:14.319989Z",
     "start_time": "2020-03-30T05:08:11.584395Z"
    }
   },
   "outputs": [],
   "source": [
    "response = session.post(\n",
    "        DR_APP_HOST + '/api/v2/batchPredictions',\n",
    "        json=job_details\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor S3 Scoring Status and Return Control Upon Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:44.938035Z",
     "start_time": "2020-03-30T05:08:14.333947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued batch job: https://app.datarobot.com/api/v2/batchPredictions/1234567891234567893/\n",
      "completed INITIALIZING\n",
      "completed RUNNING\n",
      "status is now COMPLETED\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 202:\n",
    "    \n",
    "    job = response.json()\n",
    "    print('queued batch job: {}'.format(job['links']['self']))\n",
    "\n",
    "    while job['status'] == 'INITIALIZING':\n",
    "        time.sleep(3)\n",
    "        response = session.get(job['links']['self'])\n",
    "        response.raise_for_status()\n",
    "        job = response.json()\n",
    "        \n",
    "    print('completed INITIALIZING')\n",
    "        \n",
    "    if job['status'] == 'RUNNING':\n",
    "\n",
    "        while job['status'] == 'RUNNING':\n",
    "            time.sleep(3)\n",
    "            response = session.get(job['links']['self'])\n",
    "            response.raise_for_status()\n",
    "            job = response.json()\n",
    "            \n",
    "    print('completed RUNNING')\n",
    "    print('status is now {status}'.format(status=job['status']))\n",
    "    \n",
    "    if job['status'] != 'COMPLETED':\n",
    "        for i in job['logs']:\n",
    "            print(i)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('Job submission failed; http error {code}: {content}'.format(code=response.status_code, content=response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:17:10.883806Z",
     "start_time": "2020-03-22T08:17:10.880532Z"
    }
   },
   "source": [
    "### Truncate and Reload STG Staging Table with Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:47.192679Z",
     "start_time": "2020-03-30T05:08:44.940333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<snowflake.connector.cursor.SnowflakeCursor at 0x12012c4d0>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x11fff9b50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi-statement executions\n",
    "# https://docs.snowflake.com/en/user-guide/python-connector-api.html#execute_string\n",
    "\n",
    "# truncate and load STG schema table with scored results\n",
    "sql = \"truncate titanic.stg.PASSENGERS_SCORED_BATCH_API; \" \\\n",
    "    \" copy into titanic.stg.PASSENGERS_SCORED_BATCH_API from @S3_SUPPORT/titanic/community/\" + JOB_NAME + \"_scored.csv\" \\\n",
    "    \" FILE_FORMAT = 'DEFAULT_CSV' ON_ERROR = 'ABORT_STATEMENT' PURGE = FALSE;\"\n",
    "ctx.execute_string(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-22T08:17:34.107279Z",
     "start_time": "2020-03-22T08:17:34.104603Z"
    }
   },
   "source": [
    "### Update Presentation Target Table With Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-30T05:08:52.764404Z",
     "start_time": "2020-03-30T05:08:47.195015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<snowflake.connector.cursor.SnowflakeCursor at 0x120133b50>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x120004710>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x11ff5d590>,\n",
       " <snowflake.connector.cursor.SnowflakeCursor at 0x12012c550>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# update target presentation table and ETL history table in transaction\n",
    "\n",
    "sql = \\\n",
    "    \"begin; \" \\\n",
    "    \"update titanic.public.passengers_500k_ts trg \" \\\n",
    "    \"set trg.survival = src.survived_1_prediction \" \\\n",
    "    \"from titanic.stg.PASSENGERS_SCORED_BATCH_API src \" \\\n",
    "    \"where src.passengerid = trg.passengerid; \" \\\n",
    "    \"insert into etl_history values ('{job}', '{run_through_ts}'); \" \\\n",
    "    \"commit; \".format(job=JOB_NAME, run_through_ts=end_ts)\n",
    "ctx.execute_string(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (test_env)",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
