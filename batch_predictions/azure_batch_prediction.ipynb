{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "mlops_test",
   "display_name": "mlops_test",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Code to demonstrate how to use the Batch Prediction API to score data living in an Azure Blob Storage container and output the results back to the same container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datarobot as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DataRobot connection info here\n",
    "API_KEY ='YOUR API KEY'\n",
    "BATCH_PREDICTIONS_URL = \"https://app.datarobot.com/api/v2\"\n",
    "DEPLOYMENT_ID = 'YOUR DEPLOYMENT ID'\n",
    "\n",
    "# Set Azure connection blob info here\n",
    "AZURE_STORAGE_ACCOUNT = \"YOUR AZURE STORAGE ACCOUNT NAME\"\n",
    "AZURE_STORAGE_CONTAINER = \"YOUR AZURE STORAGE ACCOUNT CONTAINER\"\n",
    "# you can get the storage access key by going to \"Access keys\" in the left menu of the storage account and use either key\n",
    "AZURE_STORAGE_ACCESS_KEY = \"AZURE STORAGE ACCOUNT ACCESS KEY\"\n",
    "\n",
    "# Set Azure input and output file names \n",
    "AZURE_INPUT_SCORING_FILE = \"YOUR INPUT SCORING FILE NAME\"\n",
    "AZURE_OUTPUT_RESULTS_FILE = \"YOUR OUTPUT RESULTS FILE NAME\"\n",
    "\n",
    "# Set name for azure credential in DataRobot\n",
    "DR_CREDENTIAL_NAME = \"Azure_{}\".format(AZURE_STORAGE_ACCOUNT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr.Client(token=API_KEY,endpoint=BATCH_PREDICTIONS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Azure-specific Credential \n",
    "# Connection String format: DefaultEndpointsProtocol=https;AccountName=****;AccountKey=****\n",
    "# The connection string is also found below the access key in Azure if you want to copy that directly.\n",
    "\n",
    "credential = dr.Credential.create_azure(\n",
    "    name=DR_CREDENTIAL_NAME,\n",
    "    azure_connection_string=\"DefaultEndpointsProtocol=https;AccountName={};AccountKey={};\".format(AZURE_STORAGE_ACCOUNT, AZURE_STORAGE_ACCESS_KEY)\n",
    ")\n",
    "\n",
    "credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to look up the ID of the credential object created.\n",
    "credential_id = None\n",
    "for cred in dr.Credential.list():\n",
    "    if cred.name == DR_CREDENTIAL_NAME:\n",
    "        credential_id = cred.credential_id\n",
    "\n",
    "print(credential_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our batch prediction job\n",
    "# Input: Azure Blob Storage\n",
    "# Output: Azure Blob Storage\n",
    "\n",
    "job = dr.BatchPredictionJob.score(\n",
    "    deployment=DEPLOYMENT_ID,\n",
    "    intake_settings={\n",
    "        'type': 'azure',\n",
    "        'url': \"https://{}.blob.core.windows.net/{}/{}\".format(AZURE_STORAGE_ACCOUNT, AZURE_STORAGE_CONTAINER,AZURE_INPUT_SCORING_FILE),\n",
    "        \"credential_id\": credential_id\n",
    "    },\n",
    "    output_settings={\n",
    "        'type': 'azure',\n",
    "        'url': \"https://{}.blob.core.windows.net/{}/{}\".format(AZURE_STORAGE_ACCOUNT, AZURE_STORAGE_CONTAINER,AZURE_OUTPUT_RESULTS_FILE),\n",
    "        \"credential_id\": credential_id\n",
    "    },\n",
    "    # If explanations are required, uncomment the line below\n",
    "    max_explanations=5,\n",
    "\n",
    "    # If passthrough columns are required, use this line\n",
    "    passthrough_columns=['column1','column2']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job.wait_for_completion()\n",
    "job.get_status()"
   ]
  }
 ]
}